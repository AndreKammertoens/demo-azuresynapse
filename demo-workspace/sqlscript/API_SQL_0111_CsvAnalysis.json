{
	"name": "API_SQL_0111_CsvAnalysis",
	"properties": {
		"description": "API Analytics Demo\nAzure Synapse Analytics Demo\nhttps://github.com/aessing/demo-azuresynapse\n\nDeveloper\nAndre Essing\n(https://www.andre-essing.de/\n(https://github.com/aessing\n(https://twitter.com/aessing\n(https://www.linkedin.com/in/aessing/)\n\nTHIS CODE AND INFORMATION ARE PROVIDED \"AS IS\" WITHOUT WARRANTY OF ANY KIND,\nEITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR PURPOSE.",
		"folder": {
			"name": "API Analytics/01 Data Engineer/02 Analysis"
		},
		"content": {
			"query": "-- =============================================================================\n-- API Analytics Demo\n-- Azure Synapse Analytics Demo\n-- https://github.com/aessing/demo-azuresynapse\n-- -----------------------------------------------------------------------------\n-- Developer.......: Andre Essing (https://www.andre-essing.de/)\n--                                (https://github.com/aessing)\n--                                (https://twitter.com/aessing)\n--                                (https://www.linkedin.com/in/aessing/)\n-- -----------------------------------------------------------------------------\n-- THIS CODE AND INFORMATION ARE PROVIDED \"AS IS\" WITHOUT WARRANTY OF ANY KIND,\n-- EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE IMPLIED\n-- WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR PURPOSE.\n-- =============================================================================\n\n-- This script is executing some statements serverless directly on the data lake\n-- At this stage in the Data Engineer workflow, we use the CSV files extracted,\n-- because we want to find some data problems in the source data if they exist\n-- before we go to the curated area.\n\n-- #############################################################################\n-- DON'T FORGET TO CHOOSE BUILT-IN\n-- #############################################################################\n\n-- -----------------------------------------------------------------------------\n-- Customer Data\n-- -----------------------------------------------------------------------------\n-- Have a direct look at the extracted data\nSELECT TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://dlsaesdwhtmp002data.dfs.core.windows.net/apianalytics/raw/Customers.csv',\n        FORMAT = 'CSV', PARSER_VERSION = '2.0', FIELDTERMINATOR = ';', HEADER_ROW = TRUE\n    ) AS [result]\n\n-- Doing some data exploration\n-- Looking for NULLS in the data\nSELECT CustomerID, CustomerName\nFROM\n    OPENROWSET(\n        BULK 'https://dlsaesdwhtmp002data.dfs.core.windows.net/apianalytics/raw/Customers.csv',\n        FORMAT = 'CSV', PARSER_VERSION = '2.0', FIELDTERMINATOR = ';', HEADER_ROW = TRUE\n    ) AS [result]\nWHERE CustomerName IS NULL\n\n-- No NULLs are found, but do we have duplicates\n-- Look for duplicated CustomerNames\nSELECT CustomerName, COUNT(1) AS 'COUNT'\nFROM\n    OPENROWSET(\n        BULK 'https://dlsaesdwhtmp002data.dfs.core.windows.net/apianalytics/raw/Customers.csv',\n        FORMAT = 'CSV', PARSER_VERSION = '2.0', FIELDTERMINATOR = ';', HEADER_ROW = TRUE\n    ) AS [result]\nGROUP BY CustomerName\nORDER BY 'COUNT' DESC\n\n-- Have a close look at the duplicates\nSELECT CustomerName, CustomerID\nFROM\n    OPENROWSET(\n        BULK 'https://dlsaesdwhtmp002data.dfs.core.windows.net/apianalytics/raw/Customers.csv',\n        FORMAT = 'CSV', PARSER_VERSION = '2.0', FIELDTERMINATOR = ';', HEADER_ROW = TRUE\n    ) AS [result]\nWHERE CustomerName IN ('Customer-220', 'Customer-160')\nORDER BY CustomerName\n\n-- -----------------------------------------------------------------------------\n-- Geo Data\n-- -----------------------------------------------------------------------------\n-- Continue data exploration on the extracted Geodata\n-- Have a look at latitude and longitude - Raw data is in millidegree, most\n-- times this is not compatible with many other apps as \"normal\" degree\nSELECT TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://dlsaesdwhtmp002data.dfs.core.windows.net/apianalytics/raw/Geodata.csv',\n        FORMAT = 'CSV', PARSER_VERSION = '2.0', FIELDTERMINATOR = ';', HEADER_ROW = TRUE\n    ) AS [result]\n\n-- Just add degree directly to the query, to see if the output is valid\nSELECT TOP 100\n    GeoID,\n    LongitudeMilliDegree,\n    LatitudeMilliDegree,\n    LongitudeMilliDegree / 1000.0 AS 'LongitudeDegree',\n    LatitudeMilliDegree / 1000.0 AS 'LatitudeDegree'    \nFROM\n    OPENROWSET(\n        BULK 'https://dlsaesdwhtmp002data.dfs.core.windows.net/apianalytics/raw/Geodata.csv',\n        FORMAT = 'CSV', PARSER_VERSION = '2.0', FIELDTERMINATOR = ';', HEADER_ROW = TRUE\n    ) AS [result]\n\n-- -----------------------------------------------------------------------------\n-- Operation Data\n-- -----------------------------------------------------------------------------\n-- Looking again for duplicated Names\n-- In this case we will find some other anomaly. Have a look at the beginning of\n-- the OperationName. Some are with and some are without slash.\n-- Also if all had a slash the estimate1* would be duplicates\nSELECT DISTINCT OperationName\nFROM\n    OPENROWSET(\n        BULK 'https://dlsaesdwhtmp002data.dfs.core.windows.net/apianalytics/raw/Operations.csv',\n        FORMAT = 'CSV', PARSER_VERSION = '2.0', FIELDTERMINATOR = ';', HEADER_ROW = TRUE\n    ) AS [result]\nORDER BY OperationName DESC\n\n-- -----------------------------------------------------------------------------\n-- Timeseries Data\n-- -----------------------------------------------------------------------------\n-- At least, we have a look at the Timeseries data\nSELECT TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://dlsaesdwhtmp002data.dfs.core.windows.net/apianalytics/raw/Timeseries.csv',\n        FORMAT = 'CSV', PARSER_VERSION = '2.0', FIELDTERMINATOR = ';', HEADER_ROW = TRUE\n    ) AS [result]\n\n-- Especially, have a look at the TimestampUtc column\n-- We will find different timestamp formats\nSELECT DISTINCT LEN(TimestampUtc) AS TimestampLength\nFROM\n    OPENROWSET(\n        BULK 'https://dlsaesdwhtmp002data.dfs.core.windows.net/apianalytics/raw/Timeseries.csv',\n        FORMAT = 'CSV', PARSER_VERSION = '2.0', FIELDTERMINATOR = ';', HEADER_ROW = TRUE\n    ) AS [result]\n\n-- Just because I'm curious, how precise the timestamps really are, when\n-- we remove the trailing '0'\nSELECT DISTINCT MAX(LEN(RTRIM(REPLACE(TimestampUtc,'0',' ')))) AS TimestampPrecision\nFROM\n    OPENROWSET(\n        BULK 'https://dlsaesdwhtmp002data.dfs.core.windows.net/apianalytics/raw/Timeseries.csv',\n        FORMAT = 'CSV', PARSER_VERSION = '2.0', FIELDTERMINATOR = ';', HEADER_ROW = TRUE\n    ) AS [result]\nORDER BY 1",
			"metadata": {
				"language": "sql"
			},
			"currentConnection": {
				"databaseName": "master",
				"poolName": "Built-in"
			},
			"resultLimit": 5000
		},
		"type": "SqlQuery"
	}
}